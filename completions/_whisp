# shellcheck disable=SC2148
# shellcheck disable=SC2034
#compdef whisper




    # Define main opts

    local -a main
    main=(
      '-o:directory to save the outputs (default: current directory)'
      '-f:format of the output file; if not specified, all available formats will be produced (default: all)'
      '--language:Set the language, if different from the audio the model will translate it.'
      '--initial_prompt:optional text to provide as a prompt for the first window. (default: None)'
      '--model:name of the Whisper model to use (default: small)'
      '--vad_filter:enable the voice activity detection (VAD) to filter out parts of the audio without speech. This step is using the Silero VAD model'
      '--live_transcribe:live transcribe mode (default: False)'
      '--hf_token HF_TOKEN:HuggingFace token which enables to download the diarization models. (default: HF_TOKEN)'
      '--verbose:whether to print out the progress and debug message (default: True)'
      '--pretty_json:produce json in a human readable format (default: False)'
      '--extras:additional arguments to pass to the model'
    )

    # Define model opts
    
    local -a extra_opts
    extra_opts=(
      '--model:name of the Whisper model to use (default: small)'
      '--model_directory:directory where to find a CTranslate2 Whisper model (e.g. fine-tuned model) (default: None)'
      '--model_dir:the path to save model files; uses ~/.cache/huggingface/ by default (default: None)'
      '--local -a:use models in cache without connecting to Internet to check if there are newer versions (default: False)'
      '--output_dir OUTPUT_DIR, -o:directory to save the outputs (default: .)'
      '--output_format {txt,vtt,srt,tsv,json,all}, -f {txt,vtt,srt,tsv,json:format of the output file; if not specified, all available formats will be produced (default: all)'
      '--pretty_json PRETTY_JSON, -p:produce json in a human readable format (default: False)'
      '--print_colors:print the transcribed text using an experimental color coding strategy to highlight words with high or low confidence (default: False)'
      '--verbose:whether to print out the progress and debug message (default: True)'
      '--highlight_words:underline each word as it is spoken in srt and vtt output formats. requires --word_timestamps True (default: False)'
      '--max_line_width:the maximum number of characters in a line before breaking the line in srt and vtt output formats. requiresword_timestamps True (default: None)'
      '--max_line_count:the maximum number of lines in a segment in srt and vtt output formats. requires --word_timestamps True) (default:None)'
      '--max_words_per_line::requires --word_timestamps True, no effect with --max_line_width the maximum number of words in a segment(default: None)'
      '--device {auto,cpu:device to use for CTranslate2 inference (default: auto)'
      '--threads:number of threads used for CPU inference (default: 0)'
      '--device_index:device ID where to place this model on (default: 0)'
      '--compute_type {default,auto,int8,int8_float16,int8_bfloat16,int8_float32,int16,float16,float32:Type of quantization to use (see https://opennmt.net/CTranslate2/quantization.html) (default: auto)'
      '--task:speech recognition transcribe or translation (default:transcribe)'
      '--language:language spoken in the audio, if None is defined the model will perform language detection'
      '--temperature:temperature to use for sampling (default: 0)'
      '--temperature_increment_on_fallback:temperature to increase when falling back when the decoding fails to meet either of the thresholds below (default:0.2)'
      '--prompt_reset_on_temperature:resets prompt if temperature is above this value. Arg has effect only if condition_on_previous_text is True(default: 0.5)'
      '--best_of:number of candidates when sampling with non-zero temperature (default: 5)'
      '--beam_size:number of beams in beam search, only applicable when temperature is zero (default: 5)'
      '--patience:optional patience value to use in beam decoding, as in https://arxiv.org/abs/2204.05424, the default (1.0) is equivalent to conventional beam search (default: 1.0)'
      '--length_penalty:optional token length penalty coefficient (alpha) as in https://arxiv.org/abs/1609.08144, uses simple length normalization by default (default: 1.0)'
      '--suppress_blank:suppress blank outputs at the beginning of the sampling (default: True)'
      '--suppress_tokens:comma-separated list of token ids to suppress during sampling; '-1' will suppress most special characters except common punctuations (default: -1)'
      '--initial_prompt:optional text to provide as a prompt for the first window. (default: None)'
      '--condition_on_previous_text:if True, provide the previous output of the model as a prompt for the next window; disabling may make the text inconsistent across windows, but the model becomes less prone to getting stuck in a failure loop (default: True)'
      '--compression_ratio_threshold:if the gzip compression ratio is higher than this value, treat the decoding as failed (default: 2.4)'
      '--logprob_threshold:if the average log probability is lower than this value, treat the decoding as failed (default: -1.0)'
      '--no_speech_threshold:if the probability of the <|nospeech|> token is higher than this value AND the decoding has failed due to logprob_threshold, consider the segment as silence (default: 0.6)'
      '--word_timestamps:(experimental) extract word-level timestamps and refine the results based on them (default: False)'
      '--prepend_punctuations:if word_timestamps is True, merge these punctuation symbols with the next word'
      '--append_punctuations:if word_timestamps is True, merge these punctuation symbols with the previous word'
      '--repetition_penalty:penalty applied to the score of previously generated tokens (set > 1 to penalize) (default: 1.0)'
      '--no_repeat_ngram_size:prevent repetitions of ngrams with this size (set 0 to disable) (default: 0)'
      '--hallucination_silence_threshold:When word_timestamps is True, skip silent periods longer than this threshold (in seconds) when a possible hallucination is detected (default: None)'
      '--vad_filter:enable the voice activity detection (VAD) to filter out parts of the audio without speech. This step is using the Silero VAD model https://github.com/snakers4/silero-vad. (default: False)'
      '--vad_threshold:when vad_filter is enabled, probabilities above this value are considered as speech. (default: None)'
      '--vad_min_speech_duration_ms:when vad_filter is enabled, final speech chunks shorter min_speech_duration_ms are thrown out. (default: None)'
      '--vad_max_speech_duration_s:when vad_filter is enabled, Maximum duration of speech chunks in seconds. Longer will be split at the:of the last silence. (default: None)'
      '--vad_min_silence_duration_ms:when vad_filter is enabled, in the end of each speech chunk time to wait before separating it. (default: None)'
      '--hf_token:HuggingFace token which enables to download the diarization models. (default: )'
      '--speaker_name:Name to use to identify the speaker (e.g. SPEAKER_00). (default: SPEAKER)'
      '--live_transcribe:live transcribe mode (default: False)'
      '--live_volume_threshold:minimum volume threshold to activate listening in live transcribe mode (default: 0.2)'
      '--live_input_device:Set live stream input device ID (see python -m sounddevice for a list) (default: None)'
    )


    # Define Models

    local -a models
    models=(
      'tiny:Tiny'
      'tiny.en:Tiny English'
      'base:Base'
      'base.en:Base English'
      'small:Small'
      'small.en:Small English'
      'medium:Medium'
      'medium.en:Medium English'
      'large-v1:Large v1'
      'large-v2:Large v2'
      'large-v3:Large v3'
      'distil-large-v2:Distil Large v2'
      'distil-large-v3:Distil Large v3'
      'distil-medium.en:Distil Medium English'
      'distil-small.en:Distil Small English'
    )

    # Define languages

    local -a languages
    languages=(
      'ar:Arabic'
      'fr:French'
      'zh:Chinese'
      'en:English'
      'fa:Persian'
      'ru:Russian'
      'iw:Hebrew'
      'es:Spanish'
      'nl:Dutch'
      'de:German'
      'hi:Hindi'
      'it:Italian'
      'ja:Japanese'
      'la:Latin'
      'sw:Swahili'
      'th:Thai'
      'tr:Turkish'
      'yi:Yiddish'
    )

    # Define output formats

    local -a output_formats
    output_formats=(
      'txt:Text'
      'vtt:VTT'
      'srt:SRT'
      'tsv:TSV'
      'json:JSON'
      'all:All'
    )

    # Define compute opts

    local -a compute
    compute=(
      'auto:Auto'
      'int8:Int8'
      'int8_float16:Int8 Float16'
      'int8_bfloat16:Int8 BFloat16'
      'int8_float32:Int8 Float32'
      'int16:Int16'
      'float16:Float16'
      'float32:Float32'
    )

    # Define devices

    local -a devices
    devices=(
      'auto:Auto'
      'cpu:CPU'
      'cuda:CUDA'
    )

    # Define true/false opts

    local -a binary_opts
    binary_opts=(
      'True:True'
      'False:False'
    )


    # Define for each case its corresponding completion rightfully titled only offer opts other than main if the previous arg is --extras
_whisp() {
    local index=$((CURRENT-1))
    local extra=false
    
    for arg in "${words[@]}"; do
        if [[ "$arg" == "--extras" ]]; then
            extra=true
        fi
    done
    if (( CURRENT == 2 )); then
       _describe -V 'Main options' main
       _files -g '(*.mp3|*.wav|*.flac|*.ogg|*.mp4|*.mkv|*.avi|*.mov|*.webm|*.wmv|*.flv)' 
    elif [[ ${words[index]} == "--model" ]]; then
        _describe -V 'Models' models
    elif [[ ${words[index]} == "--output_format" || ${words[index]} == "-f" ]]; then
        _describe -V 'Output Format' output_formats
    elif [[ ${words[index]} == "--output_dir" || ${words[index]} == "-o" ]]; then
        _files -/
    elif [[ ${words[index]} == "--language" ]]; then
        _describe -V 'Language' languages
    elif [[ ${words[index]} == "--device" ]]; then
        _describe -V 'Device' devices
    elif [[ ${words[index]} == "--compute_type" ]]; then
        _describe -V 'Compute Type' compute_opts
    elif [[ ${words[index]} == "--vad_min_silence_duration_ms" || ${words[index]} == "--vad_min_speech_duration_ms" || ${words[index]} == "--vad_max_speech_duration_s" || ${words[index]} == "--vad_threshold" || ${words[index]} == "--max_line_width" || ${words[index]} == "--max_line_count" || ${words[index]} == "--max_words_per_line" || ${words[index]} == "--temperature" || ${words[index]} == "--temperature_increment_on_fallback" || ${words[index]} == "--prompt_reset_on_temperature" || ${words[index]} == "--best_of" || ${words[index]} == "--beam_size" || ${words[index]} == "--patience" || ${words[index]} == "--length_penalty" || ${words[index]} == "--compression_ratio_threshold" || ${words[index]} == "--logprob_threshold" || ${words[index]} == "--no_speech_threshold" || ${words[index]} == "--repetition_penalty" || ${words[index]} == "--no_repeat_ngram_size" || ${words[index]} == "--hallucination_silence_threshold" || ${words[index]} == "--live_volume_threshold" ]]; then
        _message 'Number'
    elif [[ ${words[index]} == "--model_directory" || ${words[index]} == "--model_dir" ]]; then
        _files -/
    elif [[ ${words[index]} == "--hf_token" ]]; then
        _message 'HuggingFace Token'
    elif [[ ${words[index]} == "--initial_prompt" ]]; then
        _message 'Text'
    elif [[ ${words[index]} == "--speaker_name" ]]; then
        _message 'Speaker Name'
    elif [[ ${words[index]} == "--extras" ]]; then
        _describe -V 'Extra Options' extra_opts
    elif [[ extra == true ]]; then
        _describe -V 'Extra Options' extra_opts
    else
       _files -g '(*.mp3|*.wav|*.flac|*.ogg|*.mp4|*.mkv|*.avi|*.mov|*.webm|*.wmv|*.flv)' 
       _describe -V  'Main' main
    fi
}


whisp(){
    WHISP_MODEL=${WHISP_MODEL:-whisper-ctranslate2}
    WHISP_MODEL+=(--pretty_json True --print_colors True) 
    # if any arg is mentionned then we append true for args that are default set to false

    for arg in "$@"; do
        if [[ "$arg" == "--word_timestamps" ]]|| [[ "$arg" == "--live_transcribe" ]] || [[ "$arg" == "--vad_filter" ]] || [[ "$arg" == "--print_colors" ]] || [[ "$arg" == "--highlight_words" ]] || [[ "$arg" == "--pretty_json" ]] || [[ "$arg" == "--verbose" ]] || [[ "$arg" == "--condition_on_previous_text" ]] || [[ "$arg" == "--suppress_blank" ]]; then
            arg+=" true"
        elif [[ "$arg" == "--extras" ]] then
            arg=""
        fi
        WHISP_MODEL+=("$arg")
    done
    bash -c "$WHISP_MODEL"
}

compdef _whisp whisp
